{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"11wSsypaVvaa"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4649,"status":"ok","timestamp":1717741013442,"user":{"displayName":"Barani Dharan","userId":"15494022372584626808"},"user_tz":-330},"id":"dnRKLwGXV1I_","outputId":"0fb89bfc-ab0c-45e5-e5c7-6b8b480193eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 17559557.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 480847.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4338489.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 4025893.65it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","# Download and load the training data\n","trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Download and load the test data\n","testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hiVR3MnlV7Id"},"outputs":[],"source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        # Define the first convolutional layer\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        # Define the second convolutional layer\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        # Define the first fully connected layer\n","        self.fc1 = nn.Linear(9216, 128)\n","        # Define the second fully connected layer\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x) # Apply the first convolutional layer\n","        x = F.relu(x)     # Apply ReLU activation function\n","        x = self.conv2(x) # Apply the second convolutional layer\n","        x = F.relu(x)     # Apply ReLU activation function\n","        x = F.max_pool2d(x, 2) # Apply max pooling\n","        x = torch.flatten(x, 1) # Flatten the output\n","        x = self.fc1(x)   # Apply the first fully connected layer\n","        x = F.relu(x)     # Apply ReLU activation function\n","        x = self.fc2(x)   # Apply the second fully connected layer\n","        return F.log_softmax(x, dim=1) # Apply log-softmax to get probabilities\n","\n","# Create an instance of the CNN model\n","model = SimpleCNN()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hiy7Wj9AWD8c"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"73uhcmmqWHuz","outputId":"6ed44338-2851-4832-dbc3-e6c049b2d3ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.1341309791452178\n","Epoch 2, Loss: 0.040076612684278014\n","Epoch 3, Loss: 0.024992262875666964\n","Epoch 4, Loss: 0.015553804349894023\n","Epoch 5, Loss: 0.012629427209850894\n","Finished Training\n"]}],"source":["num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for images, labels in trainloader:\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","        # Print statistics\n","        running_loss += loss.item()\n","    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n","\n","print('Finished Training')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-YsCSK3WOoH"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPmFkmKi/ovr8rgh4UO+oe"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}