{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUy7ux5ifexsvkAiw2Zrcb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVMfGaweyhDh","executionInfo":{"status":"ok","timestamp":1717651137993,"user_tz":-330,"elapsed":169104,"user":{"displayName":"Barani Dharan","userId":"15494022372584626808"}},"outputId":"87decd98-3f52-448e-9e72-259999f64eb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:05<00:00, 4993667.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 206960.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3886504.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 3785462.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Epoch [1/10], Loss: 0.4887680411338806\n","Epoch [2/10], Loss: 0.3273175060749054\n","Epoch [3/10], Loss: 0.23308588564395905\n","Epoch [4/10], Loss: 0.537603497505188\n","Epoch [5/10], Loss: 0.2758738696575165\n","Epoch [6/10], Loss: 0.32536518573760986\n","Epoch [7/10], Loss: 0.34935733675956726\n","Epoch [8/10], Loss: 0.680242657661438\n","Epoch [9/10], Loss: 0.2338029444217682\n","Epoch [10/10], Loss: 0.39117303490638733\n","Training finished\n"]}],"source":["#things to note down\n","#number of epoch i use num_epoch=10(which means a single epoch pass through the entire dataset and it ensure model has seen data atleast once)\n","# iterations---epoch consist of  10 iterations  so training 10 epoch means 100 iteration /parameter updates within epoch\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","# Define a linear regression model\n","class LinearRegression(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(LinearRegression, self).__init__()\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","    def forward(self, x):\n","        return self.linear(x)\n","\n","# Load Fashion MNIST dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","\n","# Define model, loss function, and optimizer\n","model = LinearRegression(784, 10) # 784 input features (28x28 pixels), 10 output classes\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for images, labels in train_loader:\n","        images = images.view(-1, 28*28) # flatten images\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n","\n","print('Training finished')\n"]}]}